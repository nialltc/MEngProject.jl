{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using DrWatson\n",
    "@quickactivate \"MEngProject\"\n",
    "using MEngProject, CUDA, DifferentialEquations, PyPlot, NNlib,  ImageFiltering, Images, MEngProject.LaminartKernels, MEngProject.LaminartInitFunc, MEngProject.Utils, BenchmarkTools, Test\n",
    "\n",
    "using OrdinaryDiffEq, ParameterizedFunctions, LSODA, Sundials, DiffEqDevTools, Noise\n",
    "\n",
    "batch = 1\n",
    "\n",
    "\n",
    "files = readdir(datadir(\"img\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Precompiling MEngProject [d0493a11-efc0-4c7c-9b66-d0bd5a04cc55]\n",
      "└ @ Base loading.jl:1260\n",
      "┌ Info: Precompiling ImageIO [82e4d734-157c-48bb-816b-45c225c6df19]\n",
      "└ @ Base loading.jl:1260\n"
     ]
    },
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: prob not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: prob not defined",
      "",
      "Stacktrace:",
      " [1] ##core#485() at /mnt/storage_1/users/cullinanen/.julia/packages/BenchmarkTools/eCEpo/src/execution.jl:371",
      " [2] ##sample#486(::BenchmarkTools.Parameters) at /mnt/storage_1/users/cullinanen/.julia/packages/BenchmarkTools/eCEpo/src/execution.jl:377",
      " [3] _run(::BenchmarkTools.Benchmark{Symbol(\"##benchmark#484\")}, ::BenchmarkTools.Parameters; verbose::Bool, pad::String, kwargs::Base.Iterators.Pairs{Symbol,Integer,NTuple{4,Symbol},NamedTuple{(:samples, :evals, :gctrial, :gcsample),Tuple{Int64,Int64,Bool,Bool}}}) at /mnt/storage_1/users/cullinanen/.julia/packages/BenchmarkTools/eCEpo/src/execution.jl:405",
      " [4] (::Base.var\"#inner#2\"{Base.Iterators.Pairs{Symbol,Integer,NTuple{5,Symbol},NamedTuple{(:verbose, :samples, :evals, :gctrial, :gcsample),Tuple{Bool,Int64,Int64,Bool,Bool}}},typeof(BenchmarkTools._run),Tuple{BenchmarkTools.Benchmark{Symbol(\"##benchmark#484\")},BenchmarkTools.Parameters}})() at ./essentials.jl:715",
      " [5] #invokelatest#1 at ./essentials.jl:716 [inlined]",
      " [6] #run_result#37 at /mnt/storage_1/users/cullinanen/.julia/packages/BenchmarkTools/eCEpo/src/execution.jl:32 [inlined]",
      " [7] run(::BenchmarkTools.Benchmark{Symbol(\"##benchmark#484\")}, ::BenchmarkTools.Parameters; progressid::Nothing, nleaves::Float64, ndone::Float64, kwargs::Base.Iterators.Pairs{Symbol,Integer,NTuple{5,Symbol},NamedTuple{(:verbose, :samples, :evals, :gctrial, :gcsample),Tuple{Bool,Int64,Int64,Bool,Bool}}}) at /mnt/storage_1/users/cullinanen/.julia/packages/BenchmarkTools/eCEpo/src/execution.jl:94",
      " [8] #warmup#45 at /mnt/storage_1/users/cullinanen/.julia/packages/BenchmarkTools/eCEpo/src/execution.jl:141 [inlined]",
      " [9] warmup(::BenchmarkTools.Benchmark{Symbol(\"##benchmark#484\")}) at /mnt/storage_1/users/cullinanen/.julia/packages/BenchmarkTools/eCEpo/src/execution.jl:141",
      " [10] top-level scope at /mnt/storage_1/users/cullinanen/.julia/packages/BenchmarkTools/eCEpo/src/execution.jl:287",
      " [11] top-level scope at In[1]:190"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1Res_cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: prob not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: prob not defined",
      "",
      "Stacktrace:",
      " [1] ##core#522() at /mnt/storage_1/users/cullinanen/.julia/packages/BenchmarkTools/eCEpo/src/execution.jl:371",
      " [2] ##sample#523(::BenchmarkTools.Parameters) at /mnt/storage_1/users/cullinanen/.julia/packages/BenchmarkTools/eCEpo/src/execution.jl:377",
      " [3] _run(::BenchmarkTools.Benchmark{Symbol(\"##benchmark#521\")}, ::BenchmarkTools.Parameters; verbose::Bool, pad::String, kwargs::Base.Iterators.Pairs{Symbol,Integer,NTuple{4,Symbol},NamedTuple{(:samples, :evals, :gctrial, :gcsample),Tuple{Int64,Int64,Bool,Bool}}}) at /mnt/storage_1/users/cullinanen/.julia/packages/BenchmarkTools/eCEpo/src/execution.jl:405",
      " [4] (::Base.var\"#inner#2\"{Base.Iterators.Pairs{Symbol,Integer,NTuple{5,Symbol},NamedTuple{(:verbose, :samples, :evals, :gctrial, :gcsample),Tuple{Bool,Int64,Int64,Bool,Bool}}},typeof(BenchmarkTools._run),Tuple{BenchmarkTools.Benchmark{Symbol(\"##benchmark#521\")},BenchmarkTools.Parameters}})() at ./essentials.jl:715",
      " [5] #invokelatest#1 at ./essentials.jl:716 [inlined]",
      " [6] #run_result#37 at /mnt/storage_1/users/cullinanen/.julia/packages/BenchmarkTools/eCEpo/src/execution.jl:32 [inlined]",
      " [7] run(::BenchmarkTools.Benchmark{Symbol(\"##benchmark#521\")}, ::BenchmarkTools.Parameters; progressid::Nothing, nleaves::Float64, ndone::Float64, kwargs::Base.Iterators.Pairs{Symbol,Integer,NTuple{5,Symbol},NamedTuple{(:verbose, :samples, :evals, :gctrial, :gcsample),Tuple{Bool,Int64,Int64,Bool,Bool}}}) at /mnt/storage_1/users/cullinanen/.julia/packages/BenchmarkTools/eCEpo/src/execution.jl:94",
      " [8] #warmup#45 at /mnt/storage_1/users/cullinanen/.julia/packages/BenchmarkTools/eCEpo/src/execution.jl:141 [inlined]",
      " [9] warmup(::BenchmarkTools.Benchmark{Symbol(\"##benchmark#521\")}) at /mnt/storage_1/users/cullinanen/.julia/packages/BenchmarkTools/eCEpo/src/execution.jl:141",
      " [10] top-level scope at /mnt/storage_1/users/cullinanen/.julia/packages/BenchmarkTools/eCEpo/src/execution.jl:287",
      " [11] top-level scope at In[3]:86"
     ]
    }
   ],
   "source": [
    "using DrWatson\n",
    "@quickactivate \"MEngProject\"\n",
    "using MEngProject,\n",
    "    CUDA,\n",
    "    DifferentialEquations,\n",
    "    PyPlot,\n",
    "    NNlib,\n",
    "    ImageFiltering,\n",
    "    Images,\n",
    "    MEngProject.LaminartKernels,\n",
    "    MEngProject.LaminartInitFunc,\n",
    "    MEngProject.Utils,\n",
    "    BenchmarkTools,\n",
    "    Test\n",
    "\n",
    "using OrdinaryDiffEq,\n",
    "    ParameterizedFunctions, LSODA, Sundials, DiffEqDevTools, Noise\n",
    "\n",
    "batch = 1\n",
    "\n",
    "\n",
    "files = readdir(datadir(\"res_test\"))[2:end]\n",
    "\n",
    "global benchm_gpu = []\n",
    "global benchm_cpu = []\n",
    "global y1Res_gpu = []\n",
    "global y1Res_cpu = []\n",
    "\n",
    "# @inbounds begin\n",
    "    tspan = (0.0f0, 10f0)\n",
    "\n",
    "    batch_ = string(batch, \"_\", rand(1000:9999))\n",
    "    mkdir(plotsdir(string(\"bench_dim\", batch_)))\n",
    "\n",
    "\n",
    "    test_name = [\"025\", \"050\", \"075\", \"100\", \"200\", \"300\", \"400\"]\n",
    "    test_name_plt = [\n",
    "        \"\\$25×25\\$\",\n",
    "        \"\\$50×50\\$\",\n",
    "        \"\\$75×75\\$\",\n",
    "        \"\\$100×100\\$\",\n",
    "        \"\\$200×200\\$\",\n",
    "        \"\\$300×300\\$\",\n",
    "        \"\\$400×400\\$\",\n",
    "    ]\n",
    "\n",
    "\n",
    "    for file in enumerate(files[1:1])\n",
    "\n",
    "        p = LaminartInitFunc.parameterInit_conv_gpu(\n",
    "            datadir(\"res_test\", file[2]),\n",
    "            Parameters.parameters_f32,\n",
    "        )\n",
    "\n",
    "        u0 = cu(reshape(\n",
    "            zeros(Float32, p.dim_i, p.dim_j * (5 * p.K + 2)),\n",
    "            p.dim_i,\n",
    "            p.dim_j,\n",
    "            5 * p.K + 2,\n",
    "            1,\n",
    "        ))\n",
    "\n",
    "        arr1 = similar(u0[:, :, 1:2, :])\n",
    "        arr2 = similar(u0[:, :, 1:1, :])\n",
    "\n",
    "        f = LaminartFunc.LamFunction(\n",
    "            arr1, #x\n",
    "            similar(arr1), #m\n",
    "            similar(arr1), #s\n",
    "            arr2, #x_lgn,\n",
    "            similar(arr1), #C,\n",
    "            similar(arr1), #H_z,\n",
    "            similar(arr1), # dy_temp,\n",
    "            similar(arr1), # dm_temp,\n",
    "            similar(arr1), # dz_temp,\n",
    "            similar(arr1), # ds_temp,\n",
    "            similar(arr2), # dv_temp,\n",
    "            similar(arr1), # H_z_temp,\n",
    "            similar(arr2), #  V_temp_1,\n",
    "            similar(arr2), #  V_temp_2,\n",
    "            similar(arr1), #  A_temp,\n",
    "            similar(arr1), #   B_temp\n",
    "        )\n",
    "\n",
    "        prob = ODEProblem(f, u0, tspan, p)\n",
    "        push!(benchm_gpu, @benchmark solve(prob))\n",
    "        sol = solve(prob)\n",
    "\n",
    "\n",
    "        t = 10\n",
    "        v0 = @view sol(t)[:, :, :, 1]\n",
    "        axMax = findmax(v0)[1]\n",
    "\n",
    "\n",
    "        k = 7\n",
    "\t\tk2 = 8\n",
    "        fig, ax = plt.subplots()\n",
    "\n",
    "        v1 = @view sol(t)[:, :, k, 1]\n",
    "        v2 = @view sol(t)[:, :, k+1, 1]\n",
    "        im = ax.imshow(\n",
    "            v1,\n",
    "            cmap = matplotlib.cm.PRGn,\n",
    "            vmax = axMax,\n",
    "            vmin = -axMax,\n",
    "        )\n",
    "        im2 = ax.imshow(\n",
    "            v2,\n",
    "            cmap = matplotlib.cm.RdBu_r,\n",
    "            vmax = axMax,\n",
    "            vmin = -axMax,\n",
    "            alpha = 0.5,\n",
    "        )\n",
    "\n",
    "        cbar = fig.colorbar(im2, shrink = 0.9, ax = ax)\n",
    "        cbar.ax.set_xlabel(\"\\$k=$k2\\$\")\n",
    "        cbar = fig.colorbar(im, shrink = 0.9, ax = ax)\n",
    "        cbar.ax.set_xlabel(\"\\$k=$k\\$\")\n",
    "        layer = Utils.layers[k]\n",
    "        plt.title(string(\n",
    "            \"Layer: $layer, \\$t=$t\\$, resolution=\",\n",
    "            test_name_plt[file[1]],\n",
    "        ))\n",
    "        plt.axis(\"off\")\n",
    "        fig.tight_layout()\n",
    "        plt.savefig(plotsdir(\n",
    "            string(\"bench_dim\", batch_),\n",
    "            string(\n",
    "                file[2],\n",
    "                \"_res_\",\n",
    "                test_name[file[1]],\n",
    "                \"_t\",\n",
    "                t,\n",
    "                \"_\",\n",
    "                Utils.la[k],\n",
    "                \".png\",\n",
    "            ),\n",
    "        ))\n",
    "        close(\"all\")\n",
    "\n",
    "\t\tv3 = @view sol[:,:,7:7,:,:]\n",
    "\t\tpush!(y1Res, Array(v3))\n",
    "\t\tu0 = nothing\n",
    "\t\tp = nothing\n",
    "\t\tarr1 = nothing\n",
    "\t\tarr2 = nothing\n",
    "\t\tf = nothing\n",
    "\t\tprob = nothing\n",
    "\t\tsol = nothing\n",
    "\n",
    "\n",
    "\t\tp = LaminartInitFunc.parameterInit_conv_cpu(\n",
    "            datadir(\"res_test\", file[2]),\n",
    "            Parameters.parameters_f32,\n",
    "        )\n",
    "\n",
    "        u0 = reshape(\n",
    "            zeros(Float32, p.dim_i, p.dim_j * (5 * p.K + 2)),\n",
    "            p.dim_i,\n",
    "            p.dim_j,\n",
    "            5 * p.K + 2,\n",
    "            1,\n",
    "        )\n",
    "\n",
    "        arr1 = similar(u0[:, :, 1:2, :])\n",
    "        arr2 = similar(u0[:, :, 1:1, :])\n",
    "\n",
    "        f = LaminartFunc.LamFunction(\n",
    "            arr1, #x\n",
    "            similar(arr1), #m\n",
    "            similar(arr1), #s\n",
    "            arr2, #x_lgn,\n",
    "            similar(arr1), #C,\n",
    "            similar(arr1), #H_z,\n",
    "            similar(arr1), # dy_temp,\n",
    "            similar(arr1), # dm_temp,\n",
    "            similar(arr1), # dz_temp,\n",
    "            similar(arr1), # ds_temp,\n",
    "            similar(arr2), # dv_temp,\n",
    "            similar(arr1), # H_z_temp,\n",
    "            similar(arr2), #  V_temp_1,\n",
    "            similar(arr2), #  V_temp_2,\n",
    "            similar(arr1), #  A_temp,\n",
    "            similar(arr1), #   B_temp\n",
    "        )\n",
    "\n",
    "        prob = ODEProblem(f, u0, tspan, p)\n",
    "        push!(benchm_cpu, @benchmark solve(prob))\n",
    "        sol = solve(prob)\n",
    "\n",
    "\t\tpush!(y1Res_cpu, sol[:,:,7:7,:,:])\n",
    "\t\tu0 = nothing\n",
    "\t\tp = nothing\n",
    "\t\tarr1 = nothing\n",
    "\t\tarr2 = nothing\n",
    "\t\tf = nothing\n",
    "\t\tprob = nothing\n",
    "\t\tsol = nothing\n",
    "\tend\n",
    "\n",
    "    # time plot\n",
    "    fig, axs = plt.subplots()\n",
    "\n",
    "    for result ∈ enumerate(y1Res_gpu)\n",
    "\t\tlab = \"$test_name[result[1]]\"\n",
    "        axs.plot(result[2][findmax(result[2][:, :, 1, 1, end])[2][1], findmax(result[2][:, :, 1, 1, end])[2][2], k, 1, :], c = Utils.Colour[result[1]], \"--\", label = \"$lab GPU\")\n",
    "    end\n",
    "\n",
    "\tfor result ∈ enumerate(y1Res_cpu)\n",
    "\t\tlab = \"$test_name[result[1]]\"\n",
    "\t\taxs.plot(result[2][findmax(result[2][:, :, 1, 1, end])[2][1], findmax(result[2][:, :, 1, 1, end])[2][2], k, 1, :], c = Utils.Colour[result[1]],\":\", label = \"$lab CPU\")\n",
    "\tend\n",
    "    axs.set_xlabel(\"Time\")\n",
    "    axs.set_ylabel(\"Activation\")\n",
    "    plt.title(\"L2/3, \\$k=1\\$\")\n",
    "    plt.legend()\n",
    "    fig.tight_layout()\n",
    "    plt.savefig(plotsdir(\n",
    "        string(\"bench_dim\", batch_),\n",
    "        string(file[2], \"_para_\", test_name[file[1]], \"_time.png\"),\n",
    "    ))\n",
    "    close(\"all\")\n",
    "\n",
    "\n",
    "\n",
    "    # benchmark plot\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    for bm ∈ enumerate(benchm_gpu)\n",
    "        ax.scatter(\n",
    "\t\tmedian(bm[2].times) * 1e-9,\n",
    "\t\ttest_name_plt[bm[1]],\n",
    "            label = \"GPU\",\n",
    "\t\t\tcolor=Utils.colours[1],\n",
    "            alpha = 0.3,\n",
    "            edgecolors = \"none\",\n",
    "        )\n",
    "    end\n",
    "\n",
    "\tfor bm ∈ enumerate(benchm_cpu)\n",
    "\t\tax.scatter(\n",
    "            median(bm[2].times) * 1e-9,\n",
    "\t\t\ttest_name_plt[bm[1]],\n",
    "\t\t\tlabel = \"CPU\",\n",
    "\t\t\talpha = 0.3,\n",
    "\t\t\tcolor=Utils.colours[2],\n",
    "\t\t\tedgecolors = \"none\",\n",
    "\t\t)\n",
    "\tend\n",
    "\n",
    "    ax.legend()\n",
    "\taxs.set_xlabel(\"Resolution (\\$px\\$)\")\n",
    "    axs.set_ylabel(\"Time (\\$s\\$)\")\n",
    "    ax.grid(True)\n",
    "    fig.tight_layout()\n",
    "    plt.savefig(plotsdir(\n",
    "        string(\"bench_dim\", batch_),\n",
    "        string(file[2], \"_para_\", test_name[file[1]], \"_time.png\"),\n",
    "    ))\n",
    "    close(\"all\")\n",
    "\n",
    "\t# memory\n",
    "\tfig, ax = plt.subplots()\n",
    "    for bm ∈ enumerate(benchm_gpu)\n",
    "        ax.scatter(\n",
    "            bm[2].memory * 1e-6,\n",
    "            test_name_plt[bm[1]],\n",
    "\t\t\tolor=Utils.colours[1],\n",
    "            label = \"GPU\",\n",
    "            alpha = 0.3,\n",
    "            edgecolors = \"none\",\n",
    "        )\n",
    "    end\n",
    "\n",
    "    ax.legend()\n",
    "\taxs.set_xlabel(\"Resolution (\\$px\\$)\")\n",
    "    axs.set_ylabel(\"Memory\")\n",
    "    ax.grid(True)\n",
    "    fig.tight_layout()\n",
    "    plt.savefig(plotsdir(\n",
    "        string(\"bench_dim\", batch_),\n",
    "        string(file[2], \"_para_\", test_name[file[1]], \"_time.png\"),\n",
    "    ))\n",
    "    close(\"all\")\n",
    "end\n",
    "# end\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8-element Array{String,1}:\n",
       " \".ipynb_checkpoints\"\n",
       " \"ver_lines_025_gs.png\"\n",
       " \"ver_lines_050_gs.png\"\n",
       " \"ver_lines_075_gs.png\"\n",
       " \"ver_lines_100_gs.png\"\n",
       " \"ver_lines_200_gs.png\"\n",
       " \"ver_lines_300_gs.png\"\n",
       " \"ver_lines_400_gs.png\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "readdir(datadir(\"res_test\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.4.2",
   "language": "julia",
   "name": "julia-1.4"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
